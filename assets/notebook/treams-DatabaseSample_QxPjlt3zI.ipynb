{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# IBM Streams database sample application\nThis sample demonstrates creating a Streams Python application to connect to a Db2 database, performing some analytics, and viewing the results.\n\nIn this notebook, you'll see examples of how to:\n1. [Setup your database connection](#setup)\n2. [Create the application](#create)\n3. [Submit the application](#submit)\n4. [Connect to the running application to view data](#view)\n\n# Overview\n**About the sample**\n\nThis application simulates data tuples that are inserted as rows into a Db2 database table.\n\n**How it works**\n   \nThe Python application created in this notebook is submitted to the IBM Streams service for execution. Once the application is running in the service, you can connect to it from the notebook to retrieve the results.\n\n<img src=\"https://developer.ibm.com/streamsdev/wp-content/uploads/sites/15/2019/04/how-it-works.jpg\" alt=\"How it works\">\n\n\n### Documentation\n- [Streams Python development guide](https://ibmstreams.github.io/streamsx.documentation/docs/latest/python/)\n- [Streams Python API](https://streamsxtopology.readthedocs.io/)\n\n\n\n## <a name=\"setup\"> </a> 1. Setup\n\n### 1.1 Add credentials for the IBM Streams service\n\nIn order to submit a Streams application you need to provide the name of the Streams instance.\n\n1. From the navigation menu, click **My instances**.\n2. Click the **Provisioned Instances** tab.\n3. Update the value of `streams_instance_name` in the cell below according to your Streams instance name."}, {"metadata": {}, "cell_type": "code", "source": "from icpd_core import icpd_util\nstreams_instance_name = \"cp4d-streams-instance\" ## Change this to Streams instance\ncfg=icpd_util.get_service_instance_details(name=streams_instance_name)", "execution_count": 1, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### 1.2 Optional: Upgrade the `streamsx.database` Python package\n\nUncomment and run the cell below if you want to upgrade to the latest version of the streamsx.database package.\n"}, {"metadata": {}, "cell_type": "code", "source": "#!pip install --user --upgrade streamsx.database", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "The python packages will be installed in the top of user path.<br/>\nIf you have problem to get the latest version of python packages you can set the order of python packages manually to user path.<br/>\nyou can find the user path with this command:<br/>\n`\nimport sys\nfor e in sys.path:\n    print(e)\n`"}, {"metadata": {}, "cell_type": "code", "source": "#import sys\n#sys.path.insert(0, '/home/wsuser/.local/lib/python3.6/site-packages')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import streamsx.database as db\nimport streamsx.topology.context\nprint(\"INFO: streamsx package version: \" + streamsx.topology.context.__version__)\nprint(\"INFO: streamsx.database package version: \" + db.__version__)", "execution_count": 2, "outputs": [{"output_type": "stream", "text": "INFO: streamsx package version: 1.13.14\nINFO: streamsx.database package version: 1.4.0\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### <a name=\"credentials\"> </a> 1.3 Configure the connection to Db2 Warehouse\n\nWe need a Db2 credentials as JSON string to connect to a Db2 database.\nThis JSON string contains the database credentials `username`, `password` and `jdbcurl`.\n\nTo create a Db2 credentials, please perform the following steps:\n\n1. Create a Db2 Warehouse service on IBM cloud.\n\n  you need to have an IBM account to create a Db2 service.\n\n  https://console.bluemix.net/catalog/?search=db2\n\n2. Create a service credential for Db2 service on IBM cloud.\n3. Copy the credentials in clipboard.\n4. Paste the credentials into Db2 Warehouse credentials prompt below.\n\nIf you want to use another Db2 database, you can create a JSON string with the following attributes:\n\n    {\n      \"username\": \"your-db-user-name\",\n      \"password\": \"your-db-password\",\n      \"jdbcurl\": \"jdbc:db2://your-db2-hostname:50000/your-database-name\"\n    }"}, {"metadata": {}, "cell_type": "code", "source": "import getpass\ndb2_service_credentials=getpass.getpass('Db2 Warehouse credentials:')", "execution_count": 3, "outputs": [{"output_type": "error", "ename": "KeyboardInterrupt", "evalue": "", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)", "\u001b[0;32m/opt/conda/envs/Python-3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    877\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python-3.6/lib/python3.6/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python-3.6/lib/python3.6/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    466\u001b[0m         \"\"\"\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n", "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n", "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python-3.6/lib/python3.6/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n", "\u001b[0;31mKeyboardInterrupt\u001b[0m: ", "\nDuring handling of the above exception, another exception occurred:\n", "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)", "\u001b[0;32m<ipython-input-3-deb2cf572cb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdb2_service_credentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Db2 Warehouse credentials:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;32m/opt/conda/envs/Python-3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m         )\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python-3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}, {"metadata": {}, "cell_type": "code", "source": "import json\n    \nanotherdb2_service_credentials = {\n  \"username\": \"user1018\",\n  \"password\": \"cRs*B2S#v4#75@Dt\",\n  \"jdbcurl\": \"jdbc:db2://worker2:31050/BLUDB\"\n}\nanotherdb2_service_credentials_J = json.dumps(anotherdb2_service_credentials)\n# store the database credentials in db2credentials\ndb2credentials = json.loads(anotherdb2_service_credentials_J)", "execution_count": 9, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### 1.3.1 Alternative: Use a configured external connection\n\nPerform the steps [Connecting to data source](https://docs-icpdata.mybluemix.net/docs/content/SSQNUZ_current/com.ibm.icpdata.doc/igc/t_connect_data_sources.html) \nand create an external configuration for your Db2 connection.\n\nList the connections with the cell below:"}, {"metadata": {}, "cell_type": "code", "source": "ext_connections = icpd_util.get_connections('external')\nprint (ext_connections)", "execution_count": 10, "outputs": [{"output_type": "stream", "text": "[{'class': 'external', 'creator': {}, 'database_name': 'opendata', 'host': '140.110.19.12', 'name': 'epa_postgreSQL', 'port': 5432, 'type': 'PostgreSQL', 'url': 'jdbc:ibmdriver:postgresql://140.110.19.12:5432/opendata'}, {'additional_data': {'bucket_name': 'obj0708'}, 'class': 'external', 'creator': {}, 'name': 'Thomas-Data-f-streams-test', 'type': '_amazons3'}, {'additional_data': {'bucket_name': 's3.twcc.ai'}, 'class': 'external', 'creator': {}, 'name': 'twccs3', 'type': '_amazons3'}, {'class': 'external', 'creator': {}, 'database_name': 'youbike', 'host': '203.145.221.37', 'name': 'twccdb', 'port': 3306, 'type': 'MySQL-CE', 'url': 'jdbc:mysql://203.145.221.37:3306/youbike'}]\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Change the connection_name, uncomment and run the cell below "}, {"metadata": {}, "cell_type": "code", "source": "#connection_name = 'Db2-Ext'\n#db2credentials = icpd_util.get_connection(connection_name, conn_class='external')\n#print (db2credentials)", "execution_count": 11, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# <a name=\"create\"> </a> 2. Create the application\nAll Streams applications start with a Topology object, so start by creating one:\n"}, {"metadata": {}, "cell_type": "code", "source": "#Imports\nfrom streamsx.topology.topology import *\nfrom streamsx.topology.context import *\nfrom streamsx.topology.schema import StreamSchema\nimport streamsx.database as db\n\n\n# create a Topology object\ntopo = Topology(name=\"DatabaseSample\")", "execution_count": 12, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "\n### How to use the streamsx.database package\nThe streamsx.database package is the python wrapper for the [streamsx.jdbc](https://ibmstreams.github.io/streamsx.jdbc/doc/spldoc/html) toolkit\n\nTo interact with a Db2 database from Streams, you pass a SQL statement to the `streamsx.database.run_statement` function.\n\n`run_statement` is the main function of `streamsx.database` package.\n\nIt executes a SQL statement and produces a [`Stream`](https://streamsxtopology.readthedocs.io/en/stable/streamsx.topology.topology.html#stream) of the results.\nIt needs at least two mandatory parameters, the first one is the input `Stream` and the second parameter is the database credentials in JSON format.\n\nThere are 2 ways to execute SQL statements using `db.run_statement`:\n- Set the `stream` parameter to a `Stream` containing the statements to execute. This is used for statements like creating or dropping tables.\n- Set the `sql` parameter to the SQL statement and the `stream` parameter to the data you want to send to Db2. Use this when inserting data.\n\nThis application will show both ways. It executes SQL statements that: \n- Drop the Db2 table, if exists.\n- Create a new table in a Db2 database.\n- Insert some rows into the table.\n- Select all rows from a table."}, {"metadata": {}, "cell_type": "markdown", "source": "### Define the SQL statements and table name"}, {"metadata": {}, "cell_type": "code", "source": "table_name = 'RUN_SAMPLE_DEMO'\n\n# SQL statements\nsql_drop   = 'DROP TABLE ' + table_name\nsql_create = 'CREATE TABLE ' + table_name + ' (ID INT, NAME CHAR(30), AGE INT)'\nsql_insert = 'INSERT INTO ' + table_name + ' (ID, NAME, AGE) VALUES (? , ?, ?)'\nsql_select = 'SELECT * FROM ' + table_name", "execution_count": 13, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## <a name=\"drop\"> </a> 2.1. Create the table\n\n\nIn the following step the `topo.source` creates a `Stream` containing the two SQL statements to drop and create the table. \n\n`db.run_statement` executes the two statements in the input stream, so it will drop the table and create a new table.\n"}, {"metadata": {}, "cell_type": "code", "source": "# The streamToCreateTable is a Stream containing the two SQL statements: sql_drop and sql_create\nstreamToCreateTable = topo.source([sql_drop, sql_create]).as_string()\n# drop the table if exist and create a new table in database\ndb.run_statement(stream=streamToCreateTable, credentials=db2credentials, name=\"CREATE_TABLE\",)\n", "execution_count": 14, "outputs": [{"output_type": "execute_result", "execution_count": 14, "data": {"text/plain": "<streamsx.topology.topology.Stream at 0x7fdde42717b8>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## <a name=\"insert\"> </a> 2.2. Insert streaming data into the table\n\nNext, we generate a stream of data and insert it into the table we created.\n\nThe function `generate_data()` generates some data with schema `(ID INTEGER, NAME STRING, AGE INTEGER)` that will be inserted into the database..\n\nBefore it can be inserted in the database, we have to change the [schema](https://streamsxtopology.readthedocs.io/en/stable/streamsx.topology.schema.html) of the input data `Stream` to the [StreamsSchema](https://streamsxtopology.readthedocs.io/en/stable/streamsx.topology.schema.html#streamsx.topology.schema.StreamSchema) type, which is the format accepted by the `run_statement` function.  See the [list of mappings from Python types to StreamSchema types](https://streamsxtopology.readthedocs.io/en/stable/streamsx.topology.schema.html#streamsx.topology.schema.StreamSchema)\n\n\nThe `genData` `Stream` contains the data produced by the `generate_data()` function.\n\nWe again use `db.run_statement` but in the following step, it uses `genData` as input stream and the predefined `sql_insert` variable as the SQL statement.\n"}, {"metadata": {}, "cell_type": "code", "source": "import random\nimport time\n\n# generates some data with schema (ID, NAME, AGE)\ndef generate_data():\n    counter = 0\n    while True:\n        #yield a random id, name and age\n        counter = counter +1 \n        yield  {\"NAME\": \"Name_\" + str(random.randint(0,500)), \"ID\": counter, \"AGE\": random.randint(10,99)}\n        time.sleep(0.10)\n\n# convert it to SPL schema for the database operator run_statement\ntuple_schema = StreamSchema(\"tuple<int64 ID, rstring NAME, int32 AGE>\")\n# Generates data for a stream of three attributes. Each attribute maps to a column using the same name of the Db2 database table.\ngenData = topo.source(generate_data, name=\"GeneratedData\").map(lambda tpl: (tpl[\"ID\"], tpl[\"NAME\"], tpl[\"AGE\"]),\n                    schema=tuple_schema)\n\n\n# insert generated rows into table\ninsertResults= db.run_statement(name=\"INSERT\", stream=genData, sql=sql_insert, sql_params=\"ID, NAME, AGE\" ,credentials = db2credentials)", "execution_count": 15, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## <a name=\"select\"> </a> 2.3. Retrieve data from the table\nIn this step the `run_statement` runs the SQL statement `\"SELECT * FROM RUN_SAMPLE_DEMO\"` and returns the results in tuple schema `tuple<int64 ID, rstring NAME, int32 AGE>` .\n"}, {"metadata": {}, "cell_type": "code", "source": "# select all rows from table\nselectResults= db.run_statement(name=\"SELECT\", schema='tuple<int64 ID, rstring NAME, int32 AGE>', stream=genData, sql=sql_select, credentials = db2credentials)\nselectResults.print()\n\n# create a view to check retrieving data from a table\nselectView = selectResults.view(name=\"selectRecords\", description=\"Sample of selected records\")\n", "execution_count": 16, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# <a name=\"submit\"> </a> 3. Submit the application\n\nA running Streams application is called a *job*. This next cell submits the application for execution and prints the resulting job id."}, {"metadata": {}, "cell_type": "code", "source": "from streamsx.topology import context\n\n# Disable SSL certificate verification if necessary\ncfg[context.ConfigParams.SSL_VERIFY] = False\n# submit the topology 'topo'\nsubmission_result = context.submit (\"DISTRIBUTED\", topo, config = cfg)\n\n# The submission_result object contains information about the running application, or job\nif submission_result.job:\n    streams_job = submission_result.job\n    print (\"JobId: \", streams_job.id , \"\\nJob name: \", streams_job.name)", "execution_count": 17, "outputs": [{"output_type": "display_data", "data": {"text/plain": "IntProgress(value=0, bar_style='info', description='Initializing', max=10, style=ProgressStyle(description_wid\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "bb7fc52085fd4a89b62ad39ea9efdb37"}}, "metadata": {}}, {"output_type": "stream", "text": "Insecure host connections enabled.\nInsecure host connections enabled.\nInsecure host connections enabled.\n/user-home/_global_/python-3/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n  InsecureRequestWarning)\n", "name": "stderr"}, {"output_type": "stream", "text": "JobId:  59 \nJob name:  StreamsTutorialandTestbed::DatabaseSample_59\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "# <a name=\"view\"> </a> 4. Use the View to access data from the job\n\nNow that the job is started, use the View object you have already created to start retrieving data from a table in database."}, {"metadata": {}, "cell_type": "code", "source": "# Connect to the view and display the selected data\nqueue = selectView.start_data_fetch()\ntry:\n    for val in range(20):\n        print(queue.get())    \nfinally:\n    selectView.stop_data_fetch()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# <a name=\"status\"> </a> 5. See job status\n\nYou can view job status and logs by going to My Instances > Jobs. Find your job based on the id printed above. Retrieve job logs using the \"Download logs\" action from the job's context menu.\n\nTo view other information about the job such as detailed metrics, access the graph. Go to My **Instances** > **Jobs**. Select \"View graph\" action for the running job.\n\n"}, {"metadata": {}, "cell_type": "markdown", "source": "# <a name=\"cancel\"></a> 6. Cancel the job\n\nThis cell generates a widget you can use to cancel the job.\n"}, {"metadata": {}, "cell_type": "code", "source": "# cancel the job in the IBM Streams service\nsubmission_result.cancel_job_button()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "You can also interact with the job through the Job object returned from \n`submission_result.job`.\n\nFor example, use  `job.cancel()` to cancel the running job directly.\n\n## Summary\n\nWe created an application which connects to Db2 database, dropped a table, created a table, inserted some rows into table and reads the rows.\n\nAfter submitting the application to the Streams service, we checked the application logs to see the progress.\n\nIt is also possible to check the contents of the test table on Db2 console with the following command.\n\n      db2 \"SELECT * FROM RUN_SAMPLE_DEMO\"\n"}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.8", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 2}